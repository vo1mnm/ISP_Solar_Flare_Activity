# ISP_Solar_Flare_Activity

The initial question that I want to answer is whether machine learning can provide an accurate method of predicting solar flare activity based off previous data.  My motivation for wanting to predict solar flare activity using machine leaning is a result of my interests in astronomy and radio communications.  I am an amateur radio operator and have a keen interest in radio propagation.  High solar flare activity can have a tremendous effect on global communications including shortwave (HF) radio, satellites, GPS, aviation, as well as the power grid.    

Solar flares are intense emissions of electromagnetic radiation given off by the sun during but not limited to a coronal mass ejection (CME).  A CME is a large expulsion of plasma and magnetic field from the sun’s corona. The sun goes through an eleven-year cycle of high activity and low activity.  We are entering a period of high activity or solar maximum.  More sunspots on the sun equal more solar flare activity. The science behind solar flares involves stored magnetic energy in the sun’s atmosphere accelerating charged particles in surrounding plasma.  The result of this is the emission of electromagnetic radiation across the electromagnetic spectrum.  Solar flares typically erupt from active regions on the sun where magnetic fields are stronger.  The electromagnetic radiation emitted during a solar flare propagates away from the sun at the speed of light.  Excess ionizing radiation (x-rays) and extreme ultraviolet radiation (xuv) effects planetary atmosphere by increasing ionization in the Earth’s ionosphere especially impacting the D and E layers which are present in daylight hours.  The D layer is the first layer that a shortwave radio wave reaches.  It acts as an attenuator during the day.  At night, the D layer disappears when there is less ionization (this is why you can hear distant AM radio stations during night hours).  During a solar flare the D layer’s ionization increase, and radio waves are not able to be passed up into the other layers.  This temporary increase in ionization prevents shortwave (HF – high frequency) waves from propagating as skywaves, reflecting off the ionosphere, and travelling around the Earth.  During a solar flare when ionization is higher than normal, we see beautiful auroras but radio waves get degraded or completely absorbed by losing energy from frequent collisions with free electrons. 

To understand the dataset that I used, it is important to understand how the data was collected.  This data set was collected by NASA’s solar flare observatory called Reuven Ramaty High Energy Solar Spectroscopic Imager (RHESSI).  The satellite was named after NASA scientist Dr. Reuvin Ramaty who was a pioneer in high energy solar physics.  The observatory was launched on February 5, 2002.  Its primary mission was to explore the physics of particle acceleration.  RHESSI was designed to image solar flares in energetic photons from soft X-rays (~3keV) (kilo electronvolts) to gamma rays (up to ~20 MeV) and to provide high resolution spectroscopy up to gamma rays of ~ 20 MeV.  It had the ability to perform spatially resolved spectroscopy with high spectral resolution.

The goal of the RHESSI mission was to combine imaging in hard X – rays and gamma rays with high resolution spectroscopy, so that a detailed energy spectrum could be obtained at each point of the image.  This new approach that no other mission ever attempted allowed researchers to find out where these particles are accelerated and what energies they belong to. The imaging process was based on Fourier transformation technique making use of nine rotational modulation collimators.  A collimator is a device that restricts photon acceptance angles to provide positional information for detected photons.  This is how positional data was recorded for the flare dataset.  The collimators provide information about what position on the sun and/or in space the flares originated from.  Without this positional information, it would not be possible to separate solar flare radiation from other observed (non-solar flare) radiation.  

The dataset that I have chosen from the RHESSI mission was recorded from February 12, 2002, until March 3, 2018.  This dataset contains information such as start date, start time, peak, and end time stamps that mark the lifecycle of the flare.  It also includes flare duration in seconds, peak counts per second which is a measurement of peak flare intensity, and the overall number of recorded counts.  Energy in kiloelectronvolts which shows the energy range of the particles detected during the flare, x.pos.asec, and y.pos.asec are positional data that indicate where on the sun the flare originated from.  “Radial” which is the distance from the center of the sun to the flare’s position.  Active region number is the region on the sun the where the flare was detected.  Five columns (flags) are also included in the data set which represent additional information about the flare’s characteristics.  Most of the data in the dataset is relevant to the analysis as it contains information about intensity and position.  These two factors are essential when deciding what detections are registered as “flares”.  Only events with non-zero position and energy range not equal to 3-6 keV are confirmed as solar sources.  Events which have no position and show up in the front detectors, but able to be imaged are flagged as PS (no position).  For an event to be confirmed as a solar source it must have a specific location (non-zero) and its energy range must be either below 3 keV and above 6 keV.  If the energy range of the event is between 3 and 6 keV, it is not considered a solar flare source, and is probably some other form of radiation.

Libraries that I used for this analysis included pandas, numpy, sci-kit learn, matplotlib and seaborn.  The HESSI dataset was read into a pandas data frame.  When preparing the data for analysis, I first had to simplify the dataset by dealing with missing data.  I used imputation to fill missing values with zeros so that there were no null values in the dataset.  Columns representing flags 3, 4, 5 were dropped as they contained a lot of “NA” classifications.  In the cases where the energy (kiloelectronvolts) recorded a value of between 3-6 keV the flags showed the imager’s attenuator as not attenuating any incoming signals (flag: A0), flag 2 showed PS (no position detected).  As a result, flags 3, 4, and 5 were flagged NA.  In this scenario it was not measured as an actual solar flare.

In order to analyze the data I had to combine the start.date and start.time columns into a single datetime column called start.datetime and drop the original date and time columns.  A function was created to convert the energy (keV) values from string values (ex: 10-20) to numerical midpoints (ex:15) for easier numerical analysis.  New features were extracted from the datetime columns then a new binary target variable was defined called “high_activity” based on whether the peak.c/s value was greater than or equal to a threshold.  I determined the mean (average) of the total peak.c/s values and used that value as the threshold.  My threshold value of 215 allowed for a classification problem where the target is either high activity (binary = 1) or low activity (binary = 0).  The data frame was then split into features (x) and target (y).  The features include all columns except the target variable and the original peak.c/s.   One hot encoding was performed on flags 1 and 2 and they were converted into binary.  The data was then scaled using sci-kit learn standard scaler.  The feature data was scaled to have a mean of 0 and a variance of 1, this would help improve the performance of the machine learning algorithm.  The scaled data was then split into training and testing sets with 80% of the data used for training and 20% used for testing.  I decided to use random forest as the dataset had a large number of features, and it would be a good method for reducing the impact of irrelevant features or noise.  I decided to use 100 trees.  This builds multiple decision trees and uses the average prediction for classification.  The model was evaluated using metrics such as accuracy, precision, recall and F1 score and then generated a confusion matrix using seaborn to help me understand how well the model performed.  I also generated a set of hypothetical data to use for further prediction, as I did not have access to real time datasets.

My use of HPC involved running a batch shell script containing instructions for SIKU to run my python script.  My .csv dataset was a large enough to justify HPC usage, although I am sure it would have also run fine on my laptop.  The heat maps and bar chart were generated in SIKU and I pulled them along with my other files back to my local machine using the scp -r command after the script was executed.  The job only utilized 729 MB, of the 8 GB that I requested, so it was probably overkill. 

The findings of my analysis show that using a random forest method resulted in a high level of accuracy (95.19%).  Precision (89.96%) was also fairly high which indicates that the results are likely to be correct. Recall (sensitivity) and F1 score illustrate that there is a relatively high level of positive instances, and indicates a good balance between identifying true high activity cases and minimizing false findings.

The confusion matrix that I generated using seaborn resulted in a true negative of 18537, false positive of 399, false negative of 718, and a true positive of 3575.  These findings show that although there was a high level of accuracy overall, the model is better at predicting low activity vs high activity.  These findings were based on the factors such as the threshold that was used for the target variable.  In earlier trials, using a lower threshold (cutoff point) resulted in better predictability of higher activity (higher true positive).

To get a more accurate and relevant analysis it would be ideal to have access to real-time solar data.  I did not have access to a real-time dataset, so I decided to use a hypothetical (what if, made up) data to further explore possibilities regarding solar flare activity, based off my earlier findings.  I generated another correlation heat map to show these findings.  A correlation of 1 indicates a perfect positive correlation (as one variable increases, the other increases proportionally.  A value closer to -1 indicates a perfect negative correlation (as one variable increases, the other decreases proportionally.   0 would indicate no correlation.  The intensity of color (red in this case) indicates a stronger correlation.  In this case there is a very strong correlation between duration.s and energy.kev (0.98). This indicates that as the duration increases, the energy measured in keV also increases, which suggests that the longer the event lasts, the more energy it produces (stronger flare).  Total.counts and probability_of_high_activity (0.91) also shows a strong correlation, and suggests that as the total count increases, the probability of high activity also increases.  This implies that higher counts are a good indicator of high activity.  Predicted_high_activity and probability_of_high_activity (0.89) shows a strong positive correlation, and indicates a good alignment between predictions and actual probability of activity.   

The biggest obstacle faced when undertaking this analysis was understanding the data set.  It appeared quite confusing at first, but once I understood the importance of “positional data” and how the satellite detected flare data relating to intensity, it became much clearer.  The flag data was also complex and took some investigation to understand its purpose in the dataset.  I also struggled with finding an appropriate threshold to use for the target variable.  I originally used a lower one, which yielded higher true positive activity (high activity).  I decided to find the average value of the peak.c/s column and use that as my threshold hoping that it would give a more “general” clarification. 


In conclusion, although the findings reported a high level of accuracy, I don’t feel fully confident that this is great method for predicting solar flare activity.  The sun is always active, changing, and requires a high level of monitoring.  If there was more access to real-time and current data it could be used as a great starting point for further analysis, along with some finer tuning of parameters.


References

DATASET found at: https://www.kaggle.com/datasets/khsamaha/solar-flares-rhessi

https://www.analyticsvidhya.com/blog/2024/03/how-can-deep-learning-be-applied-to-predict-solar-flares/#

https://www.swpc.noaa.gov/phenomena/solar-flares-radio-blackouts

https://en.wikipedia.org/wiki/Solar_flare

http://www.hydroquebec.com/learning/notions-de-base/tempete-mars-1989.html

https://spaceweatherarchive.com/2020/08/30/a-warning-from-history-the-carrington-event-was-not-unique/

https://www.arrl.org/files/file/Technology/pdf/119962.pdf

https://medium.com/codex/why-scaling-your-data-is-important-1aff95ca97a2#:~:text=Data%20scaling%20is%20the%20process,the%20performance%20of%20the%20algorithm.

https://www.sciencedirect.com/science/article/abs/pii/S2213133721000226

https://www.linkedin.com/pulse/secrets-sun-random-forests-trees-solar-activity-roxy-williams-qfvie

https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html

https://www.qsl.net/4x4xm/HF-Propagation.htm

https://imagesofoldhawaii.com/carrington-event/

https://hesperia.gsfc.nasa.gov/rhessi3/docs/qlook/hsi_flare_list.html

https://en.wikipedia.org/wiki/Reuven_Ramaty_High_Energy_Solar_Spectroscopic_Imager






